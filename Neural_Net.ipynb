{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import chess\n",
    "import chess.pgn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following Board Representation from Paper\n",
    "def bit_board_encoder(board):\n",
    "    bit_boards = {\"P\": np.zeros(64),\"N\": np.zeros(64),\"B\": np.zeros(64),\n",
    "                  \"R\": np.zeros(64),\"Q\": np.zeros(64),\"K\": np.zeros(64),\n",
    "                  \"p\": np.zeros(64),\"n\": np.zeros(64),\"b\": np.zeros(64),\n",
    "                  \"r\": np.zeros(64),\"q\": np.zeros(64),\"k\": np.zeros(64)}\n",
    "    for i in range(0, 64):\n",
    "        square = board.piece_at(i)\n",
    "        if square is not None:\n",
    "            if square.symbol().isupper():\n",
    "                bit_boards[square.symbol()][i] = 1\n",
    "            else:\n",
    "                bit_boards[square.symbol()][i] = 1\n",
    "            \n",
    "    bit_board = np.concatenate([bit_boards[\"P\"], bit_boards[\"R\"], bit_boards[\"N\"], bit_boards[\"B\"], \n",
    "                                bit_boards[\"Q\"], bit_boards[\"K\"], bit_boards[\"p\"], bit_boards[\"r\"],\n",
    "                                bit_boards[\"n\"], bit_boards[\"b\"], bit_boards[\"q\"], bit_boards[\"k\"]])\n",
    "    return bit_board\n",
    "\n",
    "#All Pieces on one board\n",
    "def board_encoder(board):\n",
    "    board_rep = np.zeros(64);\n",
    "    for i in range(0, 64):\n",
    "        square = board.piece_at(i)\n",
    "        if square is not None:\n",
    "            board_rep[i] = {\"P\": 1,\"N\": 3,\"B\": 3.3,\n",
    "                            \"R\": 5,\"Q\": 9.5,\"K\": 10,\n",
    "                            \"p\": 1,\"n\": 3,\"b\": 3.3,\n",
    "                            \"r\": 5,\"q\": 9.5,\"k\": 10}[square.symbol()]\n",
    "            \n",
    "    return board_rep\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stockfish = pandas.read_csv('C:\\\\Users\\\\Christopher.Atkeson\\\\Documents\\\\web_project\\\\chess_evaluation\\\\stockfish.csv')\n",
    "#pgn = open('C:\\\\Users\\\\Christopher.Atkeson\\\\Documents\\\\web_project\\\\chess_evaluation\\\\data.pgn')\n",
    "stockfish = pandas.read_csv('/Users/chrisatkeson/Documents/web_project/chess_evaluation/stockfish.csv')\n",
    "pgn = open('/Users/chrisatkeson/Documents/web_project/chess_evaluation/data.pgn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "evaluations = stockfish['MoveScores'];\n",
    "all_evaluations = [];\n",
    "all_positions =[];\n",
    "all_moves = [];\n",
    "\n",
    "count = 0\n",
    "\n",
    "for game in evaluations:\n",
    "    count = count+1\n",
    "    if count % 500 == 0:\n",
    "        print(count)\n",
    "    position = chess.pgn.read_game(pgn)\n",
    "    for evaluation in game.split():\n",
    "        all_positions.append(position.board())\n",
    "        next_position = position.variations[0]\n",
    "        position = next_position\n",
    "        if evaluation.isdigit():\n",
    "            all_evaluations.append([float(evaluation)])\n",
    "        elif evaluation.lstrip('-').isdigit():\n",
    "            all_evaluations.append([float(evaluation.lstrip('-'))*-1.0])\n",
    "        else: \n",
    "            all_evaluations.append([0])\n",
    "\n",
    "    if count == 5000:\n",
    "        break\n",
    "        \n",
    "#normalize evaluations      \n",
    "standard_dev = np.stdev(all_evaluations)\n",
    "mean_evaluation = np.mean(all_evaluations)\n",
    "max_evaluation = np.max(all_evaluations)\n",
    "min_evaluation = np.min(all_evaluations)\n",
    "max_abs_evaluation = max(max_evaluation, min_evaluation*-1.0)\n",
    "\n",
    "normalized_evaluations = np.asarray(all_evaluations) * 1/max_abs_evaluation\n",
    "\n",
    "#Constuct Board Vectors\n",
    "positions = []\n",
    "for position in all_positions:\n",
    "    positions.append(bit_board_encoder(position))\n",
    "    \n",
    "positions, normalized_evaluations = shuffle(positions, normalized_evaluations, random_state=0)\n",
    "\n",
    "num_rows = len(positions)\n",
    "num_cols_x = 768\n",
    "num_cols_y = 1\n",
    "\n",
    "X = np.zeros((num_rows,num_cols_x))\n",
    "Y = np.zeros((num_rows,num_cols_y))\n",
    "\n",
    "for k in range(0,num_rows):\n",
    "    X[k,:] = positions[k][:]\n",
    "    Y[k,:] = normalized_evaluations[k][:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:300000]\n",
    "X_test = X[300001:400000]\n",
    "\n",
    "Y_train = Y[0:300000]\n",
    "Y_test = Y[300001:400000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 0.0026\n",
      "Epoch 2/5\n",
      "300000/300000 [==============================] - 70s 234us/step - loss: 0.0017\n",
      "Epoch 3/5\n",
      "300000/300000 [==============================] - 70s 234us/step - loss: 0.0014\n",
      "Epoch 4/5\n",
      "300000/300000 [==============================] - 73s 243us/step - loss: 0.0012\n",
      "Epoch 5/5\n",
      "300000/300000 [==============================] - 71s 237us/step - loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201454c50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keras Model\n",
    "\n",
    "n_input = 768 # 12 8x8 chessboards\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, activation = 'relu', input_shape=(n_input,)))\n",
    "model.add(Dense(250, activation = 'relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1,activation='tanh'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random: 0.005\n",
    "score = model.evaluate(X_test, Y_test, batch_size=50)\n",
    "print(score)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(Y_test[0:99999], predictions[0:99999], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Net\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 100 # 1st layer number of neurons\n",
    "n_hidden_2 = 100 # 2nd layer number of neurons\n",
    "n_input = 768 # 12 8x8 chessboards\n",
    "n_classes = 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    out_layer = tf.nn.tanh(out_layer)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99159807 1.01985145 1.01022673 ... 0.92674917 0.95122498 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "output = multilayer_perceptron(X)\n",
    "# using mean squared error cost function\n",
    "cost  = tf.square(output - Y)\n",
    "# using Gradient Descent algorithm\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    cost_history=[]\n",
    "    \n",
    "    for step in np.arange(1):\n",
    "        for x in range(0,100):\n",
    "            start = x*100\n",
    "            end = start+999\n",
    "            sess.run(optimizer, feed_dict={X:positions[start:end], Y:normalized_evaluations[start:end]})\n",
    "            cost_history = np.append(cost_history, sess.run(cost,feed_dict={X:positions[start:end], Y:normalized_evaluations[start:end]}))\n",
    "    \n",
    "        print(cost_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00145725 0.0013763  0.0009715  ... 0.83273964 0.83273964 0.83330635]\n"
     ]
    }
   ],
   "source": [
    "print(normalized_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess_evaluation",
   "language": "python",
   "name": "chess_evaluation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
